# Agent Prompt Train Configuration Example
# Copy this file to .env and update with your values

# ===================
# Required Settings
# ===================

# PostgreSQL connection string
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/agent_prompttrain

# ===================
# Dashboard Authentication
# ===================

# Development: Set user email for local development (bypasses oauth2-proxy)
# ⚠️ ONLY use this in development! Do NOT set in production!
DASHBOARD_DEV_USER_EMAIL=dev@localhost

# Production: Configure oauth2-proxy headers (mandatory in production)
# The dashboard extracts user email from these headers set by oauth2-proxy
DASHBOARD_SSO_HEADERS=X-Auth-Request-Email
DASHBOARD_SSO_ALLOWED_DOMAINS=

# AWS ALB OIDC: Enable ALB OIDC authentication via x-amzn-oidc-data header
# When enabled, the dashboard will decode the JWT from AWS ALB and extract the email claim
# Note: This implementation does not verify JWT signatures. Use with caution.
DASHBOARD_ALB_OIDC_ENABLED=false

# Google OAuth2 configuration for oauth2-proxy
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
# Generate 32 byte base64 string: `openssl rand -base64 32`
OAUTH_PROXY_COOKIE_SECRET=

# ===================
# Claude API Settings
# ===================

# API keys are managed through credential files in the credentials/ directory
# See credentials/README.md for setup instructions

# Directory for domain credential files (default: ./credentials)
CREDENTIALS_DIR=./credentials

# Wildcard credential support (default: false)
# true = Enable wildcard matching, false = Disable, shadow = Log only (no behavior change)
# When enabled, _wildcard.example.com.credentials.json matches all subdomains of example.com
CNP_WILDCARD_CREDENTIALS=false

# TTL for credential resolution cache in milliseconds (default: 300000 = 5 minutes)
# Caches both successful and failed credential lookups for performance
CNP_RESOLUTION_CACHE_TTL=300000

# Enable debug logging for credential resolution (default: false)
# Logs detailed information about domain matching and wildcard resolution
CNP_DEBUG_RESOLUTION=false

# ===================
# Service Configuration
# ===================

# Service mode (full|proxy|api) - Controls which endpoints are active
# - full: All endpoints (default, backward compatible) - Claude Code + Dashboard API
# - proxy: Only Claude Code endpoints (/v1/*, /mcp, /health, /token-stats)
# - api: Only Dashboard API endpoints (/api/*, /health)
# Note: api mode requires DATABASE_URL and INTERNAL_API_KEY
SERVICE_MODE=full

# Proxy service
HOST=0.0.0.0

# Dashboard service
DASHBOARD_PORT=3001
DASHBOARD_HOST=0.0.0.0

# Service-to-service authentication (dashboard → proxy API)
# Used for internal communication between dashboard and proxy services
# Generate with: openssl rand -base64 32
# Required when SERVICE_MODE=api or SERVICE_MODE=full
INTERNAL_API_KEY=your-internal-api-key-here

# ===================
# Feature Flags
# ===================

# Enable request/response storage (default: false)
STORAGE_ENABLED=true

# Enable debug logging - masks sensitive data (default: false)
DEBUG=false

# Enable SQL query logging (default: false)
# Shows all SQL queries in debug logs when running the application
DEBUG_SQL=false

# Require client authentication (default: true)
# Set to false for easier testing with Claude Code
ENABLE_CLIENT_AUTH=false

# ===================
# Performance Tuning
# ===================

# Dashboard cache TTL in seconds, 0 to disable (default: 30)
DASHBOARD_CACHE_TTL=30

# Log queries slower than this threshold in ms (default: 5000)
SLOW_QUERY_THRESHOLD_MS=5000

# ===================
# Monitoring & Alerts
# ===================

# Slack webhook for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
SLACK_CHANNEL=#alerts
SLACK_USERNAME="PromptTrain"
SLACK_ICON_EMOJI=:robot_face:
SLACK_ENABLED=false

# Telemetry endpoint (optional)
TELEMETRY_ENDPOINT=

# ===================
# MCP (Model Context Protocol) Settings
# ===================

# Enable MCP server (default: false)
MCP_ENABLED=false

# Local prompts directory (default: ./prompts)
# Store your prompt YAML files in this directory
MCP_PROMPTS_DIR=./prompts

# Watch for file changes and hot-reload (default: true)
# Useful for development - automatically reloads prompts when files change
MCP_WATCH_FILES=true

# Cache settings
MCP_CACHE_TTL=300        # Cache TTL in seconds (not currently used with file-based system)
MCP_CACHE_SIZE=1000      # Max prompts in memory cache

# ===================
# Optional: GitHub Sync Configuration
# ===================
# Enable GitHub sync to fetch prompts from a repository
# When configured, prompts will be synced from GitHub and written to MCP_PROMPTS_DIR

# GitHub repository owner (user or organization)
# MCP_GITHUB_OWNER=your-org

# GitHub repository name
# MCP_GITHUB_REPO=prompt-library

# Branch to sync from (default: main)
# MCP_GITHUB_BRANCH=main

# GitHub personal access token with repo read permissions
# MCP_GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxx

# Path within the repository containing prompt files (default: prompts/)
# MCP_GITHUB_PATH=prompts/

# Sync interval in seconds (default: 300 / 5 minutes)
# MCP_SYNC_INTERVAL=300

# ===================
# Development Settings
# ===================

# Collect request samples for testing (default: false)
COLLECT_TEST_SAMPLES=false

# Directory for test samples (default: test-samples)
TEST_SAMPLES_DIR=test-samples

# Proxy API URL for dashboard (default: http://localhost:3000)
PROXY_API_URL=http://localhost:3000

# ===================
# AI Analysis Configuration
# ===================

# Background Worker Settings
AI_WORKER_ENABLED=false
AI_WORKER_POLL_INTERVAL_MS=5000
AI_WORKER_MAX_CONCURRENT_JOBS=3
AI_WORKER_JOB_TIMEOUT_MINUTES=5
AI_ANALYSIS_MAX_RETRIES=3
AI_ANALYSIS_GEMINI_REQUEST_TIMEOUT_MS=60000

# Gemini API Configuration
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1beta/models
GEMINI_MODEL_NAME=gemini-2.0-flash-exp

# Analysis Token Limits
AI_ANALYSIS_INPUT_TRUNCATION_TARGET_TOKENS=8192
AI_ANALYSIS_TRUNCATE_FIRST_N_TOKENS=1000
AI_ANALYSIS_TRUNCATE_LAST_M_TOKENS=4000
