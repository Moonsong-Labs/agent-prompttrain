{
  "description": "Test linking between 24e0f740-f2b3-4716-984d-48a6fcc309e1 and ff58c4c0-a0b8-42a4-b238-3ff3f1190063",
  "type": "compact",
  "expectedIsSubtask": true,
  "expectedParentTaskRequestId": "24e0f740-f2b3-4716-984d-48a6fcc309e1",
  "parent": {
    "request_id": "24e0f740-f2b3-4716-984d-48a6fcc309e1",
    "domain": "localhost:3000",
    "conversation_id": "f2304222-a3db-4924-af42-5884286cb610",
    "branch_id": "main",
    "current_message_hash": "87161bc2a4aa18d49e389cc001bda9dc5c6869270fb7c215481fccda1b7fde5c",
    "parent_message_hash": null,
    "system_hash": "890b3a8ca71b4f2b14e96102f6d027b9216a3443364b7b75cdba94c27ac81c18",
    "body": {
      "model": "claude-opus-4-20250514",
      "stream": true,
      "system": [
        {
          "text": "You are Claude Code, Anthropic's official CLI for Claude.",
          "type": "text",
          "cache_control": {
            "type": "ephemeral"
          }
        },
        {
          "text": "\nYou are an interactive CLI tool that helps users with software engineering tasks. Use the instructions below and the tools available to you to assist the user.\n\nIMPORTANT: Assist with defensive security tasks only. Refuse to create, modify, or improve code that may be used maliciously. Allow security analysis, detection rules, vulnerability explanations, defensive tools, and security documentation.\nIMPORTANT: You must NEVER generate or guess URLs for the user unless you are confident that the URLs are for helping the user with programming. You may use URLs provided by the user in their messages or local files.\n\nIf the user asks for help or wants to give feedback inform them of the following: \n- /help: Get help with using Claude Code\n- To give feedback, users should report the issue at https://github.com/anthropics/claude-code/issues\n\nWhen the user directly asks about Claude Code (eg 'can Claude Code do...', 'does Claude Code have...') or asks in second person (eg 'are you able...', 'can you do...'), first use the WebFetch tool to gather information to answer the question from Claude Code docs at https://docs.anthropic.com/en/docs/claude-code.\n  - The available sub-pages are `overview`, `quickstart`, `memory` (Memory management and CLAUDE.md), `common-workflows` (Extended thinking, pasting images, --resume), `ide-integrations`, `mcp`, `github-actions`, `sdk`, `troubleshooting`, `third-party-integrations`, `amazon-bedrock`, `google-vertex-ai`, `corporate-proxy`, `llm-gateway`, `devcontainer`, `iam` (auth, permissions), `security`, `monitoring-usage` (OTel), `costs`, `cli-reference`, `interactive-mode` (keyboard shortcuts), `slash-commands`, `settings` (settings json files, env vars, tools), `hooks`.\n  - Example: https://docs.anthropic.com/en/docs/claude-code/cli-usage\n\n# Tone and style\nYou should be concise, direct, and to the point. When you run a non-trivial bash command, you should explain what the command does and why you are running it, to make sure the user understands what you are doing (this is especially important when you are running a command that will make changes to the user's system).\nRemember that your output will be displayed on a command line interface. Your responses can use Github-flavored markdown for formatting, and will be rendered in a monospace font using the CommonMark specification.\nOutput text to communicate with the user; all text you output outside of tool use is displayed to the user. Only use tools to complete tasks. Never use tools like Bash or code comments as means to communicate with the user during the session.\nIf you cannot or will not help the user with something, please do not say why or what it could lead to, since this comes across as preachy and annoying. Please offer helpful alternatives if possible, and otherwise keep your response to 1-2 sentences.\nOnly use emojis if the user explicitly requests it. Avoid using emojis in all communication unless asked.\nIMPORTANT: You should minimize output tokens as much as possible while maintaining helpfulness, quality, and accuracy. Only address the specific query or task at hand, avoiding tangential information unless absolutely critical for completing the request. If you can answer in 1-3 sentences or a short paragraph, please do.\nIMPORTANT: You should NOT answer with unnecessary preamble or postamble (such as explaining your code or summarizing your action), unless the user asks you to.\nIMPORTANT: Keep your responses short, since they will be displayed on a command line interface. You MUST answer concisely with fewer than 4 lines (not including tool use or code generation), unless user asks for detail. Answer the user's question directly, without elaboration, explanation, or details. One word answers are best. Avoid introductions, conclusions, and explanations. You MUST avoid text before/after your response, such as \"The answer is <answer>.\", \"Here is the content of the file...\" or \"Based on the information provided, the answer is...\" or \"Here is what I will do next...\". Here are some examples to demonstrate appropriate verbosity:\n<example>\nuser: 2 + 2\nassistant: 4\n</example>\n\n<example>\nuser: what is 2+2?\nassistant: 4\n</example>\n\n<example>\nuser: is 11 a prime number?\nassistant: Yes\n</example>\n\n<example>\nuser: what command should I run to list files in the current directory?\nassistant: ls\n</example>\n\n<example>\nuser: what command should I run to watch files in the current directory?\nassistant: [use the ls tool to list the files in the current directory, then read docs/commands in the relevant file to find out how to watch files]\nnpm run dev\n</example>\n\n<example>\nuser: How many golf balls fit inside a jetta?\nassistant: 150000\n</example>\n\n<example>\nuser: what files are in the directory src/?\nassistant: [runs ls and sees foo.c, bar.c, baz.c]\nuser: which file contains the implementation of foo?\nassistant: src/foo.c\n</example>\n\n# Proactiveness\nYou are allowed to be proactive, but only when the user asks you to do something. You should strive to strike a balance between:\n1. Doing the right thing when asked, including taking actions and follow-up actions\n2. Not surprising the user with actions you take without asking\nFor example, if the user asks you how to approach something, you should do your best to answer their question first, and not immediately jump into taking actions.\n3. Do not add additional code explanation summary unless requested by the user. After working on a file, just stop, rather than providing an explanation of what you did.\n\n# Following conventions\nWhen making changes to files, first understand the file's code conventions. Mimic code style, use existing libraries and utilities, and follow existing patterns.\n- NEVER assume that a given library is available, even if it is well known. Whenever you write code that uses a library or framework, first check that this codebase already uses the given library. For example, you might look at neighboring files, or check the package.json (or cargo.toml, and so on depending on the language).\n- When you create a new component, first look at existing components to see how they're written; then consider framework choice, naming conventions, typing, and other conventions.\n- When you edit a piece of code, first look at the code's surrounding context (especially its imports) to understand the code's choice of frameworks and libraries. Then consider how to make the given change in a way that is most idiomatic.\n- Always follow security best practices. Never introduce code that exposes or logs secrets and keys. Never commit secrets or keys to the repository.\n\n# Code style\n- IMPORTANT: DO NOT ADD ***ANY*** COMMENTS unless asked\n\n\n# Task Management\nYou have access to the TodoWrite and TodoRead tools to help you manage and plan tasks. Use these tools VERY frequently to ensure that you are tracking your tasks and giving the user visibility into your progress.\nThese tools are also EXTREMELY helpful for planning tasks, and for breaking down larger complex tasks into smaller steps. If you do not use this tool when planning, you may forget to do important tasks - and that is unacceptable.\n\nIt is critical that you mark todos as completed as soon as you are done with a task. Do not batch up multiple tasks before marking them as completed.\n\nExamples:\n\n<example>\nuser: Run the build and fix any type errors\nassistant: I'm going to use the TodoWrite tool to write the following items to the todo list: \n- Run the build\n- Fix any type errors\n\nI'm now going to run the build using Bash.\n\nLooks like I found 10 type errors. I'm going to use the TodoWrite tool to write 10 items to the todo list.\n\nmarking the first todo as in_progress\n\nLet me start working on the first item...\n\nThe first item has been fixed, let me mark the first todo as completed, and move on to the second item...\n..\n..\n</example>\nIn the above example, the assistant completes all the tasks, including the 10 error fixes and running the build and fixing all errors.\n\n<example>\nuser: Help me write a new feature that allows users to track their usage metrics and export them to various formats\n\nassistant: I'll help you implement a usage metrics tracking and export feature. Let me first use the TodoWrite tool to plan this task.\nAdding the following todos to the todo list:\n1. Research existing metrics tracking in the codebase\n2. Design the metrics collection system\n3. Implement core metrics tracking functionality\n4. Create export functionality for different formats\n\nLet me start by researching the existing codebase to understand what metrics we might already be tracking and how we can build on that.\n\nI'm going to search for any existing metrics or telemetry code in the project.\n\nI've found some existing telemetry code. Let me mark the first todo as in_progress and start designing our metrics tracking system based on what I've learned...\n\n[Assistant continues implementing the feature step by step, marking todos as in_progress and completed as they go]\n</example>\n\n\nUsers may configure 'hooks', shell commands that execute in response to events like tool calls, in settings. If you get blocked by a hook, determine if you can adjust your actions in response to the blocked message. If not, ask the user to check their hooks configuration.\n\n# Doing tasks\nThe user will primarily request you perform software engineering tasks. This includes solving bugs, adding new functionality, refactoring code, explaining code, and more. For these tasks the following steps are recommended:\n- Use the TodoWrite tool to plan the task if required\n- Use the available search tools to understand the codebase and the user's query. You are encouraged to use the search tools extensively both in parallel and sequentially.\n- Implement the solution using all tools available to you\n- Verify the solution if possible with tests. NEVER assume specific test framework or test script. Check the README or search codebase to determine the testing approach.\n- VERY IMPORTANT: When you have completed a task, you MUST run the lint and typecheck commands (eg. npm run lint, npm run typecheck, ruff, etc.) with Bash if they were provided to you to ensure your code is correct. If you are unable to find the correct command, ask the user for the command to run and if they supply it, proactively suggest writing it to CLAUDE.md so that you will know to run it next time.\nNEVER commit changes unless the user explicitly asks you to. It is VERY IMPORTANT to only commit when explicitly asked, otherwise the user will feel that you are being too proactive.\n\n- Tool results and user messages may include <system-reminder> tags. <system-reminder> tags contain useful information and reminders. They are NOT part of the user's provided input or the tool result.\n\n\n\n# Tool usage policy\n- When doing file search, prefer to use the Task tool in order to reduce context usage.\n- You have the capability to call multiple tools in a single response. When multiple independent pieces of information are requested, batch your tool calls together for optimal performance. When making multiple bash tool calls, you MUST send a single message with multiple tools calls to run the calls in parallel. For example, if you need to run \"git status\" and \"git diff\", send a single message with two tool calls to run the calls in parallel.\n\nYou MUST answer concisely with fewer than 4 lines of text (not including tool use or code generation), unless user asks for detail.\n\n\nHere is useful information about the environment you are running in:\n<env>\nWorking directory: /home/crystalin/projects/claude-nexus-proxy\nIs directory a git repo: Yes\nAdditional working directories: /tmp\nPlatform: linux\nOS Version: Linux 5.15.167.4-microsoft-standard-WSL2\nToday's date: 2025-07-01\n</env>\nYou are powered by the model named Opus 4. The exact model ID is claude-opus-4-20250514.\n\n\nIMPORTANT: Assist with defensive security tasks only. Refuse to create, modify, or improve code that may be used maliciously. Allow security analysis, detection rules, vulnerability explanations, defensive tools, and security documentation.\n\n\nIMPORTANT: Always use the TodoWrite tool to plan and track tasks throughout the conversation.\n\n\n# Code References\n\nWhen referencing specific functions or pieces of code include the pattern `file_path:line_number` to allow the user to easily navigate to the source code location.\n\n<example>\nuser: Where are errors from the client handled?\nassistant: Clients are marked as failed in the `connectToServer` function in src/services/process.ts:712.\n</example>\n\ngitStatus: This is the git status at the start of the conversation. Note that this status is a snapshot in time, and will not update during the conversation.\nCurrent branch: feature/subtask-conversation-linking\n\nMain branch (you will usually use this for PRs): main\n\nStatus:\nM packages/shared/src/utils/__tests__/conversation-linker.test.ts\n M packages/shared/src/utils/conversation-linker.ts\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/09-simple-subtask.json\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/10-subtask-detection.json\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/11-subtask-single-message.json\n\nRecent commits:\n0e2ceab feat: re-implement is_subtask support for Task tool conversations\n134d11d fix: convert nanoid to UUID in linkConversation to prevent SQL errors (#59)\n1684af4 fix: ensure shared package is built before dashboard typecheck (#61)\n052e79f feat: add exec command to manage-nexus-proxies.sh (#58)\ne228e82 feat: improve dashboard UI with 5 enhancements (#53)",
          "type": "text",
          "cache_control": {
            "type": "ephemeral"
          }
        }
      ],
      "messages": [
        {
          "role": "user",
          "content": [
            {
              "text": "<system-reminder>\nAs you answer the user's questions, you can use the following context:\n# claudeMd\nCodebase and user instructions are shown below. Be sure to adhere to these instructions. IMPORTANT: These instructions OVERRIDE any default behavior and you MUST follow them exactly as written.\n\nContents of /home/crystalin/projects/claude-nexus-proxy/CLAUDE.md (project instructions, checked into the codebase):\n\n# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with this repository.\n\n## Project Overview\n\nClaude Nexus Proxy - A high-performance proxy for Claude API with monitoring dashboard. Built with Bun and Hono framework, deployed as separate Docker images for each service.\n\n## Architectural Decision Records (ADRs)\n\nTechnical decisions are documented in `docs/ADRs/`. Key architectural decisions:\n\n- **ADR-001**: Example ADR\n- **ADR-012**: Database Schema Evolution Strategy - TypeScript migrations with init SQL\n- **ADR-013**: TypeScript Project References - Monorepo type checking solution\n\n**AI Assistant Directive**: When discussing architecture or making technical decisions, always reference relevant ADRs. If a new architectural decision is made during development, create or update an ADR to document it. This ensures all technical decisions have clear rationale and can be revisited if needed.\n\n## Architecture\n\n### Monorepo Structure\n\n```\nclaude-nexus-proxy/\n├── packages/shared/      # Shared types and configurations\n├── services/\n│   ├── proxy/           # Proxy API service (Port 3000)\n│   └── dashboard/       # Dashboard web service (Port 3001)\n├── scripts/             # Utility scripts\n├── docker/              # Docker configurations\n│   ├── proxy/           # Proxy Dockerfile\n│   └── dashboard/       # Dashboard Dockerfile\n├── docker-compose.yml   # Container orchestration\n├── .env                 # Proxy/Dashboard configuration\n└── credentials/         # Domain credentials (Claude Auth, Slack, ...)\n\n\n```\n\n### Key Services\n\n**Proxy Service** (`services/proxy/`)\n\n- Direct API forwarding to Claude\n- Multi-auth support (API keys, OAuth with auto-refresh)\n- Token tracking and telemetry\n- Request/response storage\n- Slack notifications\n\n**Dashboard Service** (`services/dashboard/`)\n\n- Monitoring UI\n- Analytics and usage charts\n- Request history browser\n- SSE for live updates\n\n## Development\n\n```bash\n# Install dependencies\nbun install\n\n# Run both services\nbun run dev\n\n# Run individually\nbun run dev:proxy      # Port 3000\nbun run dev:dashboard  # Port 3001\n\n# Build\nbun run build\n```\n\n### Git Pre-commit Hooks\n\nThe project uses Husky and lint-staged for automated code quality checks:\n\n```bash\n# Pre-commit hooks are automatically installed via postinstall script\nbun install\n\n# Manual hook installation (if needed)\nbunx husky init\n```\n\n**Pre-commit checks:**\n\n- ESLint fixes for TypeScript/JavaScript files\n- Prettier formatting for all supported file types\n- Automatic fixes are applied when possible\n\n**Note:** TypeScript type checking is not included in pre-commit hooks for performance reasons. Type checking runs in CI/CD pipeline.\n\n## Docker Deployment\n\nThe project uses **separate Docker images** for each service:\n\n```bash\n# Build images\n./docker/build-images.sh\n\n# Run proxy service\ndocker run -p 3000:3000 alanpurestake/claude-nexus-proxy:latest\n\n# Run dashboard service\ndocker run -p 3001:3001 alanpurestake/claude-nexus-dashboard:latest\n```\n\nDocker configurations are in the `docker/` directory. Each service has its own optimized image for better security, scaling, and maintainability.\n\n### Docker Compose Environment\n\ndocker/docker-compose.yml: Postgres + Proxy + Dashboard + Claude CLI (with ccusage and token monitoring). `./docker-up.sh` script is used instead of `docker compose -f ...` to ensure `.env` is loaded properly.\n\n```bash\n# Build the local images\n./docker-up.sh build\n\n# Run the full environment (requires real Claude account in )\n./docker-up.sh up -d\n\n# Run a claude query\n./docker-up.sh exec claude-cli claude \"hi\"\n\n# Run usage monitor for real-time tracking\n./docker-up.sh exec claude-cli monitor\n\n# Check daily usage stats\n./docker-up.sh exec claude-cli ccusage daily\n```\n\n## Key Implementation Details\n\n### Request Timeout Configuration\n\nThe proxy supports long-running Claude API requests with configurable timeouts:\n\n- **Default timeout**: 10 minutes (600,000ms) for Claude API requests\n- **Server timeout**: 11 minutes (660,000ms) to prevent premature connection closure\n- **Retry timeout**: Slightly longer than request timeout to allow for retries\n- Configure via `CLAUDE_API_TIMEOUT` and `PROXY_SERVER_TIMEOUT` environment variables\n\n### Conversation Tracking & Branching\n\nThe proxy automatically tracks conversations and detects branches using message hashing:\n\n**How it works:**\n\n1. Each message in a request is hashed using SHA-256\n2. The current message hash and parent message hash (previous message) are stored\n3. Requests are linked into conversations by matching parent/child relationships\n4. Conversations support branching (like git) when resumed from earlier points\n5. Branches are automatically detected when multiple requests share the same parent\n6. When multiple conversations have the same parent hash, the system picks the conversation with the fewest requests to continue\n7. Messages continue on the same branch as their parent unless they create a new branch point\n\n**Message Normalization:**\n\n- String content and array content are normalized to produce consistent hashes\n- Example: `\"hello\"` and `[{type: \"text\", text: \"hello\"}]` produce the same hash\n- **System reminders are filtered out**: Content items starting with `<system-reminder>` are ignored during hashing\n- **Duplicate messages are deduplicated**: When tool_use or tool_result messages have duplicate IDs, only the first occurrence is included in the hash\n- This ensures conversations link correctly regardless of content format, system reminder presence, or duplicate messages from the Claude API\n\n**Dual Hash System:**\n\n- **Message Hash**: Used for conversation linking, contains only message content\n- **System Hash**: Tracks system prompt separately, stored in `system_hash` column\n- This allows conversations to maintain links even when system prompts change (e.g., git status updates, context compaction)\n- Backward compatible: Old conversations continue to work without modification\n\n**Special Conversation Handling:**\n\n- **Conversation Summarization**: When Claude summarizes a conversation (detected by system prompt \"You are a helpful AI assistant tasked with summarizing conversations\"), the system links to the previous conversation ignoring system prompt differences\n- **Compact Conversations**: When a conversation is continued from a previous one due to context overflow (first message starts with \"This session is being continued from a previous conversation...\"), it:\n  - Links to the source conversation automatically\n  - Creates a special branch ID format: `compact_HHMMSS`\n  - Preserves the compact branch for all follow-up messages in that conversation\n  - Prevents unnecessary branching when continuing compact conversations\n\n**API Endpoints:**\n\n- `/api/conversations` - Get conversations grouped by conversation_id with branch information\n- Query parameters: `domain` (filter by domain), `limit` (max conversations)\n\n**Database Schema:**\n\n- `conversation_id` - UUID identifying the conversation\n- `current_message_hash` - Hash of the last message in the request\n- `parent_message_hash` - Hash of the previous message (null for first message)\n- `system_hash` - Hash of the system prompt (for tracking context changes)\n- `branch_id` - Branch identifier (defaults to 'main', auto-generated for new branches)\n- `parent_request_id` - Direct link to the parent request in the conversation chain\n\n**Dashboard Features:**\n\n- **Conversations View** - Visual timeline showing message flow and branches\n- **Branch Visualization** - Blue nodes indicate branch points\n- **Branch Labels** - Non-main branches are labeled with their branch ID\n- **Conversation Grouping** - All related requests grouped under one conversation\n- **Multiple Tool Display** - Messages with multiple tool_use or tool_result blocks are properly displayed with visual separation (horizontal rules between each tool invocation)\n- **Duplicate Filtering** - Duplicate tool_use and tool_result blocks (same ID) are automatically filtered out\n- **System Reminder Filtering** - System reminder text blocks are hidden from display\n\n### Authentication Flow\n\n**Client Authentication (Proxy Level):**\n\n1. Extract domain from Host header\n2. Check for `client_api_key` in domain credential file\n3. Verify Bearer token against stored key using timing-safe comparison\n4. Return 401 Unauthorized if invalid\n\n**Claude API Authentication:**\n\n1. Check domain-specific credential files (`<domain>.credentials.json`)\n2. Use Authorization header from request\n\n### OAuth Support\n\n- Auto-refresh tokens 1 minute before expiry\n- Stores refreshed tokens back to credential files\n- Adds `anthropic-beta: oauth-2025-04-20` header\n\n### Token Tracking\n\n**In-Memory Tracking (Legacy)**\n\n- Per-domain statistics\n- Request type classification (query evaluation vs inference)\n- Tool call counting\n- Available at `/token-stats` endpoint\n\n**Comprehensive Token Usage Tracking (New)**\n\n- Tracks ALL request types (including query_evaluation and quota)\n- Persistent storage in partitioned `token_usage` table\n- 5-hour rolling window support for monitoring Claude API limits\n- Per-account AND per-domain tracking\n- API endpoints:\n  - `/api/token-usage/current` - Current window usage\n  - `/api/token-usage/daily` - Historical daily usage data\n  - `/api/conversations` - Conversations with account info\n- **Note**: Rate limiting is handled by Claude API directly. The proxy only tracks and displays usage statistics.\n\n### Storage\n\n- PostgreSQL for request/response data\n- Write-only access from proxy\n- Read-only access from dashboard\n- Automatic batch processing\n- **Conversation Grouping**: Requests are automatically grouped by conversation using message hashing\n\n### Debug Logging\n\nWhen `DEBUG=true`:\n\n- Logs full request/response (with sensitive data masked)\n- Shows streaming chunks\n- Masks patterns: `sk-ant-****`, `Bearer ****`\n- Includes SQL query stack traces\n\n### SQL Query Logging\n\nEnable SQL query logging in debug mode:\n\n```bash\n# Option 1: Enable all debug logging (includes SQL)\nDEBUG=true bun run dev\n\n# Option 2: Enable only SQL query logging\nDEBUG_SQL=true bun run dev\n\n# Option 3: Set in .env file\nDEBUG_SQL=true\n```\n\nSQL logging features:\n\n- All queries with parameters\n- Query execution time\n- Row counts\n- Slow query warnings (default: >5 seconds)\n- Failed query errors with details\n\n## Environment Variables\n\n**Essential:**\n\n- `DATABASE_URL` - PostgreSQL connection\n- `DASHBOARD_API_KEY` - Dashboard authentication\n\n**Optional:**\n\n- `DEBUG` - Enable debug logging\n- `DEBUG_SQL` - Enable SQL query logging (default: false)\n- `STORAGE_ENABLED` - Enable storage (default: false)\n- `SLACK_WEBHOOK_URL` - Slack notifications\n- `CREDENTIALS_DIR` - Domain credential directory\n- `COLLECT_TEST_SAMPLES` - Collect request samples for testing (default: false)\n- `TEST_SAMPLES_DIR` - Directory for test samples (default: test-samples)\n- `ENABLE_CLIENT_AUTH` - Enable client API key authentication (default: true). Set to false to allow anyone to use the proxy without authentication\n- `DASHBOARD_CACHE_TTL` - Dashboard cache TTL in seconds (default: 30). Set to 0 to disable caching\n- `SLOW_QUERY_THRESHOLD_MS` - Threshold in milliseconds for logging slow SQL queries (default: 5000)\n- `CLAUDE_API_TIMEOUT` - Timeout for Claude API requests in milliseconds (default: 600000 / 10 minutes)\n- `PROXY_SERVER_TIMEOUT` - Server-level timeout in milliseconds (default: 660000 / 11 minutes)\n- `STORAGE_ADAPTER_CLEANUP_MS` - Interval for cleaning up orphaned request ID mappings in milliseconds (default: 300000 / 5 minutes)\n- `STORAGE_ADAPTER_RETENTION_MS` - Retention time for request ID mappings in milliseconds (default: 3600000 / 1 hour)\n- `API_KEY_SALT` - Salt for hashing API keys in database (default: 'claude-nexus-proxy-default-salt')\n- `SPARK_API_URL` - Spark API base URL for recommendation feedback (default: 'http://localhost:8000')\n- `SPARK_API_KEY` - API key for authenticating with Spark API\n\n## Important Notes\n\n### Request Metadata\n\n- Query evaluation and quota are not part of the conversation, they serve as metadata queries\n\n## Testing & Type Safety\n\n**Type Checking:**\n\n- Run `bun run typecheck` before committing\n- Type checking is automatic during builds\n- Fix all type errors before deploying\n- **TypeScript Project References**: The monorepo uses TypeScript Project References for proper dependency management\n  - Automatically handles build order between packages\n  - Generates declaration files for cross-package imports\n  - Run `tsc --build` at the root to type check all packages\n  - See ADR-013 for details on this architectural decision\n\n**Test Sample Collection:**\nThe proxy can collect real request samples for test development:\n\n- Enable with `COLLECT_TEST_SAMPLES=true`\n- Samples are stored in `test-samples/` directory\n- Each request type gets its own file (e.g., `inference_streaming_opus.json`)\n- Sensitive data is automatically masked\n- Samples include headers, body, and metadata\n\n**Tests:**\nCurrently no automated tests. When implementing:\n\n- Use Bun's built-in test runner\n- Test proxy logic, telemetry, token tracking\n- Test both streaming and non-streaming responses\n- Use collected samples as test data\n\n## Important Notes\n\n- Uses Bun runtime exclusively (no Node.js)\n- Separate Docker images for each service\n- TypeScript compilation for production builds\n- Model-agnostic (accepts any model name)\n\n## Database Schema\n\n### Main Tables\n\n**api_requests** - Stores all API requests and responses with token tracking:\n\n- `account_id` - Account identifier from credential files for per-account tracking\n- `input_tokens`, `output_tokens`, `total_tokens` - Token usage metrics\n- `conversation_id`, `branch_id` - Conversation tracking\n- `current_message_hash`, `parent_message_hash` - Message linking\n- `parent_task_request_id`, `is_subtask`, `task_tool_invocation` - Sub-task tracking\n\n**streaming_chunks** - Stores streaming response chunks\n\n### Account-Based Token Tracking\n\nToken usage is tracked directly in the `api_requests` table:\n\n- Each request is associated with an `account_id` from the credential file\n- Token counts are stored per request for accurate tracking\n- Queries aggregate usage by account and time window\n\n### Database Schema Evolution\n\n**Schema Management:**\n\n- Initial schema: `scripts/init-database.sql`\n- Migrations: `scripts/db/migrations/` (TypeScript files)\n- Auto-initialization: `writer.ts` uses init SQL file when tables don't exist\n\n**Running Migrations:**\n\n```bash\n# Run a specific migration\nbun run scripts/db/migrations/001-add-conversation-tracking.ts\n\n# Run all migrations in order\nfor file in scripts/db/migrations/*.ts; do bun run \"$file\"; done\n```\n\n**Available Migrations:**\n\n- 000: Initial database setup\n- 001: Add conversation tracking\n- 002: Optimize conversation indexes\n- 003: Add sub-task tracking\n- 004: Optimize window function queries\n- 005: Populate account IDs\n\nSee `docs/04-Architecture/ADRs/adr-012-database-schema-evolution.md` for details.\n\n## Common Tasks\n\n### Add Domain Credentials\n\n```bash\n# Generate secure client API key\nbun run scripts/generate-api-key.ts\n\n# Create credential file\ncat > credentials/domain.com.credentials.json << EOF\n{\n  \"type\": \"api_key\",\n  \"accountId\": \"acc_f9e1c2d3b4a5\",  # Unique account identifier\n  \"api_key\": \"sk-ant-...\",\n  \"client_api_key\": \"cnp_live_...\"\n}\nEOF\n```\n\n### Enable Storage\n\n```bash\nexport STORAGE_ENABLED=true\nexport DATABASE_URL=postgresql://...\n```\n\n### View Token Stats\n\n```bash\ncurl http://localhost:3000/token-stats\n```\n\n### Access Dashboard\n\n```bash\nopen http://localhost:3001\n# Use DASHBOARD_API_KEY for authentication\n# Auth header: X-Dashboard-Key: <your-key>\n```\n\n## Sub-task Tracking & Visualization\n\n### Sub-task Detection\n\nThe proxy automatically detects and tracks sub-tasks spawned using the Task tool:\n\n**Database Fields:**\n\n- `parent_task_request_id` - Links sub-task requests to their parent task\n- `is_subtask` - Boolean flag indicating if a request is a sub-task\n- `task_tool_invocation` - JSONB array storing Task tool invocations\n\n**Sub-task Linking:**\n\n- Sub-tasks are linked by matching the user message to Task tool invocation prompts\n- The system creates parent-child relationships between tasks and their sub-tasks\n- Multiple sub-tasks can be spawned from a single parent request\n\n### Dashboard Visualization\n\n**Conversation Tree:**\n\n- Sub-task nodes appear as separate gray boxes to the right of parent nodes\n- Format: \"sub-task N (M)\" where N is the sub-task number and M is the message count\n- Sub-task boxes are clickable and link to their conversation\n- Hover over sub-task boxes to see the task prompt in a tooltip\n\n**Stats Display:**\n\n- \"Total Sub-tasks\" panel shows count of all sub-tasks in a conversation\n- Sub-task indicators on parent nodes show number of spawned tasks\n\n**Visual Design:**\n\n- Sub-task boxes: 100x36px gray boxes with 150px right offset\n- Tooltips: 250x130px with gradient background, appear above nodes on hover\n- Connected to parent nodes with horizontal edges\n\n## Important Implementation Notes\n\n### Conversation Hash Filtering\n\nWhen generating message hashes for conversation tracking, the system filters out:\n\n- Content items that start with `<system-reminder>`\n- This prevents conversation linking from breaking when Claude adds system reminders\n\n### Dashboard Authentication\n\n- Uses `X-Dashboard-Key` header (not Authorization)\n- Cookie-based auth also supported for browser sessions\n\n### Spark Tool Integration\n\nThe dashboard supports the Spark recommendation tool (`mcp__spark__get_recommendation`):\n\n**Features:**\n\n- Automatic detection of Spark tool usage in conversations\n- Display of recommendations in a formatted view\n- Feedback UI for rating and commenting on recommendations\n- Batch fetching of existing feedback\n- Integration with Spark API for feedback submission\n\n**Configuration:**\n\n1. Set `SPARK_API_URL` and `SPARK_API_KEY` environment variables\n2. The dashboard will automatically detect Spark recommendations in tool_result messages\n3. Users can submit feedback directly from the request details page\n4. The proxy logs Spark configuration at startup:\n   - When configured: Shows URL and confirms API key is set\n   - When not configured: Shows \"SPARK_API_KEY not set\"\n\n**API Endpoints:**\n\n- `POST /api/spark/feedback` - Submit feedback for a recommendation\n- `GET /api/spark/sessions/:sessionId/feedback` - Get feedback for a specific session\n- `POST /api/spark/feedback/batch` - Get feedback for multiple sessions\n\n**Security Note:**\n\nThe dashboard authentication cookie (`dashboard_auth`) is set with `httpOnly: false` to allow JavaScript access for making authenticated API calls from the browser to the proxy service. This is a security trade-off that enables the inline feedback component to work. Consider implementing a more secure approach such as:\n\n- Using a separate API token for browser-based requests\n- Implementing a server-side proxy endpoint in the dashboard\n- Using session-based authentication with CSRF tokens\n\n### SQL Query Optimization\n\n- Always include all required fields in SELECT statements\n- Missing fields like `parent_task_request_id`, `is_subtask`, `task_tool_invocation` will break sub-task tracking\n- Use the SLOW_QUERY_THRESHOLD_MS env var to monitor query performance\n\n### Check Token Usage\n\n```bash\n# Current 5-hour window usage\ncurl \"http://localhost:3000/api/token-usage/current?accountId=acc_f9e1c2d3b4a5&window=300\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n\n# Daily usage (last 30 days)\ncurl \"http://localhost:3000/api/token-usage/daily?accountId=acc_f9e1c2d3b4a5&aggregate=true\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n\n# View conversations\ncurl \"http://localhost:3000/api/conversations?accountId=acc_f9e1c2d3b4a5\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n```\n\n### Copy Conversation Between Databases\n\n```bash\n# Copy a conversation from one database to another\nbun run db:copy-conversation --conversation-id <uuid> --dest-db <url> [options]\n\n# Example: Copy to staging database (same table names)\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\"\n\n# Dry run to preview what would be copied\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" --dry-run\n\n# Copy with streaming chunks\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" --include-chunks\n\n# Use custom table names (e.g., from api_requests to api_requests_backup)\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" \\\n  --source-table api_requests --dest-table api_requests_backup\n```\n\n## Maintenance\n\n### Grooming\n\nThe process of `grooming` is used to keep a clean repository. It should be performed regularly and rely on [GROOMING.md](GROOMING.md)\n\n# important-instruction-reminders\nDo what has been asked; nothing more, nothing less.\nNEVER create files unless they're absolutely necessary for achieving your goal.\nALWAYS prefer editing an existing file to creating a new one.\nNEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.\n\n      \n      IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context or otherwise consider it in your response unless it is highly relevant to your task. Most of the time, it is not relevant.\n</system-reminder>\n",
              "type": "text"
            },
            {
              "text": "create a subtask to count files",
              "type": "text"
            },
            {
              "text": "<system-reminder>This is a reminder that your todo list is currently empty. DO NOT mention this to the user explicitly because they are already aware. If you are working on tasks that would benefit from a todo list please use the TodoWrite tool to create one. If not, please feel free to ignore. Again do not mention this message to the user.</system-reminder>",
              "type": "text",
              "cache_control": {
                "type": "ephemeral"
              }
            }
          ]
        }
      ],
      "metadata": {
        "user_id": "claude-1"
      },
      "max_tokens": 32000,
      "temperature": 1
    },
    "response_body": {
      "id": "msg_01KCuZobHN8P4FQvH1FwtdTc",
      "role": "assistant",
      "type": "message",
      "model": "claude-opus-4-20250514",
      "usage": {
        "input_tokens": 4,
        "service_tier": "standard",
        "output_tokens": 166,
        "cache_read_input_tokens": 0,
        "cache_creation_input_tokens": 44563
      },
      "content": [
        {
          "text": "I'll create a subtask to count files in the codebase.",
          "type": "text"
        },
        {
          "id": "toolu_01C5VCDqeUtJsuQrQrA91Lp5",
          "name": "Task",
          "type": "tool_use",
          "input": {
            "prompt": "Count all files in the codebase, broken down by:\n1. Total number of files\n2. Files by type/extension (e.g., .ts, .json, .md, etc.)\n3. Files per directory (services/proxy, services/dashboard, packages/shared, etc.)\n\nProvide a summary with the counts organized in a clear format.",
            "description": "Count files in codebase"
          }
        }
      ],
      "stop_reason": "tool_use",
      "stop_sequence": null
    }
  },
  "child": {
    "request_id": "ff58c4c0-a0b8-42a4-b238-3ff3f1190063",
    "domain": "localhost:3000",
    "body": {
      "model": "claude-opus-4-20250514",
      "stream": true,
      "system": [
        {
          "text": "You are Claude Code, Anthropic's official CLI for Claude.",
          "type": "text",
          "cache_control": {
            "type": "ephemeral"
          }
        },
        {
          "text": "You are an agent for Claude Code, Anthropic's official CLI for Claude. Given the user's message, you should use the tools available to complete the task. Do what has been asked; nothing more, nothing less. When you complete the task simply respond with a detailed writeup.\n\nNotes:\n- NEVER create files unless they're absolutely necessary for achieving your goal. ALWAYS prefer editing an existing file to creating a new one.\n- NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.\n- In your final response always share relevant file names and code snippets. Any file paths you return in your response MUST be absolute. Do NOT use relative paths.\n- For clear communication with the user the assistant MUST avoid using emojis.\n\nHere is useful information about the environment you are running in:\n<env>\nWorking directory: /home/crystalin/projects/claude-nexus-proxy\nIs directory a git repo: Yes\nAdditional working directories: /tmp\nPlatform: linux\nOS Version: Linux 5.15.167.4-microsoft-standard-WSL2\nToday's date: 2025-07-01\n</env>\nYou are powered by the model named Opus 4. The exact model ID is claude-opus-4-20250514.\n\ngitStatus: This is the git status at the start of the conversation. Note that this status is a snapshot in time, and will not update during the conversation.\nCurrent branch: feature/subtask-conversation-linking\n\nMain branch (you will usually use this for PRs): main\n\nStatus:\nM packages/shared/src/utils/__tests__/conversation-linker.test.ts\n M packages/shared/src/utils/conversation-linker.ts\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/09-simple-subtask.json\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/10-subtask-detection.json\n?? packages/shared/src/utils/__tests__/fixtures/conversation-linking/11-subtask-single-message.json\n\nRecent commits:\n0e2ceab feat: re-implement is_subtask support for Task tool conversations\n134d11d fix: convert nanoid to UUID in linkConversation to prevent SQL errors (#59)\n1684af4 fix: ensure shared package is built before dashboard typecheck (#61)\n052e79f feat: add exec command to manage-nexus-proxies.sh (#58)\ne228e82 feat: improve dashboard UI with 5 enhancements (#53)",
          "type": "text",
          "cache_control": {
            "type": "ephemeral"
          }
        }
      ],
      "messages": [
        {
          "role": "user",
          "content": [
            {
              "text": "<system-reminder>\nAs you answer the user's questions, you can use the following context:\n# claudeMd\nCodebase and user instructions are shown below. Be sure to adhere to these instructions. IMPORTANT: These instructions OVERRIDE any default behavior and you MUST follow them exactly as written.\n\nContents of /home/crystalin/projects/claude-nexus-proxy/CLAUDE.md (project instructions, checked into the codebase):\n\n# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with this repository.\n\n## Project Overview\n\nClaude Nexus Proxy - A high-performance proxy for Claude API with monitoring dashboard. Built with Bun and Hono framework, deployed as separate Docker images for each service.\n\n## Architectural Decision Records (ADRs)\n\nTechnical decisions are documented in `docs/ADRs/`. Key architectural decisions:\n\n- **ADR-001**: Example ADR\n- **ADR-012**: Database Schema Evolution Strategy - TypeScript migrations with init SQL\n- **ADR-013**: TypeScript Project References - Monorepo type checking solution\n\n**AI Assistant Directive**: When discussing architecture or making technical decisions, always reference relevant ADRs. If a new architectural decision is made during development, create or update an ADR to document it. This ensures all technical decisions have clear rationale and can be revisited if needed.\n\n## Architecture\n\n### Monorepo Structure\n\n```\nclaude-nexus-proxy/\n├── packages/shared/      # Shared types and configurations\n├── services/\n│   ├── proxy/           # Proxy API service (Port 3000)\n│   └── dashboard/       # Dashboard web service (Port 3001)\n├── scripts/             # Utility scripts\n├── docker/              # Docker configurations\n│   ├── proxy/           # Proxy Dockerfile\n│   └── dashboard/       # Dashboard Dockerfile\n├── docker-compose.yml   # Container orchestration\n├── .env                 # Proxy/Dashboard configuration\n└── credentials/         # Domain credentials (Claude Auth, Slack, ...)\n\n\n```\n\n### Key Services\n\n**Proxy Service** (`services/proxy/`)\n\n- Direct API forwarding to Claude\n- Multi-auth support (API keys, OAuth with auto-refresh)\n- Token tracking and telemetry\n- Request/response storage\n- Slack notifications\n\n**Dashboard Service** (`services/dashboard/`)\n\n- Monitoring UI\n- Analytics and usage charts\n- Request history browser\n- SSE for live updates\n\n## Development\n\n```bash\n# Install dependencies\nbun install\n\n# Run both services\nbun run dev\n\n# Run individually\nbun run dev:proxy      # Port 3000\nbun run dev:dashboard  # Port 3001\n\n# Build\nbun run build\n```\n\n### Git Pre-commit Hooks\n\nThe project uses Husky and lint-staged for automated code quality checks:\n\n```bash\n# Pre-commit hooks are automatically installed via postinstall script\nbun install\n\n# Manual hook installation (if needed)\nbunx husky init\n```\n\n**Pre-commit checks:**\n\n- ESLint fixes for TypeScript/JavaScript files\n- Prettier formatting for all supported file types\n- Automatic fixes are applied when possible\n\n**Note:** TypeScript type checking is not included in pre-commit hooks for performance reasons. Type checking runs in CI/CD pipeline.\n\n## Docker Deployment\n\nThe project uses **separate Docker images** for each service:\n\n```bash\n# Build images\n./docker/build-images.sh\n\n# Run proxy service\ndocker run -p 3000:3000 alanpurestake/claude-nexus-proxy:latest\n\n# Run dashboard service\ndocker run -p 3001:3001 alanpurestake/claude-nexus-dashboard:latest\n```\n\nDocker configurations are in the `docker/` directory. Each service has its own optimized image for better security, scaling, and maintainability.\n\n### Docker Compose Environment\n\ndocker/docker-compose.yml: Postgres + Proxy + Dashboard + Claude CLI (with ccusage and token monitoring). `./docker-up.sh` script is used instead of `docker compose -f ...` to ensure `.env` is loaded properly.\n\n```bash\n# Build the local images\n./docker-up.sh build\n\n# Run the full environment (requires real Claude account in )\n./docker-up.sh up -d\n\n# Run a claude query\n./docker-up.sh exec claude-cli claude \"hi\"\n\n# Run usage monitor for real-time tracking\n./docker-up.sh exec claude-cli monitor\n\n# Check daily usage stats\n./docker-up.sh exec claude-cli ccusage daily\n```\n\n## Key Implementation Details\n\n### Request Timeout Configuration\n\nThe proxy supports long-running Claude API requests with configurable timeouts:\n\n- **Default timeout**: 10 minutes (600,000ms) for Claude API requests\n- **Server timeout**: 11 minutes (660,000ms) to prevent premature connection closure\n- **Retry timeout**: Slightly longer than request timeout to allow for retries\n- Configure via `CLAUDE_API_TIMEOUT` and `PROXY_SERVER_TIMEOUT` environment variables\n\n### Conversation Tracking & Branching\n\nThe proxy automatically tracks conversations and detects branches using message hashing:\n\n**How it works:**\n\n1. Each message in a request is hashed using SHA-256\n2. The current message hash and parent message hash (previous message) are stored\n3. Requests are linked into conversations by matching parent/child relationships\n4. Conversations support branching (like git) when resumed from earlier points\n5. Branches are automatically detected when multiple requests share the same parent\n6. When multiple conversations have the same parent hash, the system picks the conversation with the fewest requests to continue\n7. Messages continue on the same branch as their parent unless they create a new branch point\n\n**Message Normalization:**\n\n- String content and array content are normalized to produce consistent hashes\n- Example: `\"hello\"` and `[{type: \"text\", text: \"hello\"}]` produce the same hash\n- **System reminders are filtered out**: Content items starting with `<system-reminder>` are ignored during hashing\n- **Duplicate messages are deduplicated**: When tool_use or tool_result messages have duplicate IDs, only the first occurrence is included in the hash\n- This ensures conversations link correctly regardless of content format, system reminder presence, or duplicate messages from the Claude API\n\n**Dual Hash System:**\n\n- **Message Hash**: Used for conversation linking, contains only message content\n- **System Hash**: Tracks system prompt separately, stored in `system_hash` column\n- This allows conversations to maintain links even when system prompts change (e.g., git status updates, context compaction)\n- Backward compatible: Old conversations continue to work without modification\n\n**Special Conversation Handling:**\n\n- **Conversation Summarization**: When Claude summarizes a conversation (detected by system prompt \"You are a helpful AI assistant tasked with summarizing conversations\"), the system links to the previous conversation ignoring system prompt differences\n- **Compact Conversations**: When a conversation is continued from a previous one due to context overflow (first message starts with \"This session is being continued from a previous conversation...\"), it:\n  - Links to the source conversation automatically\n  - Creates a special branch ID format: `compact_HHMMSS`\n  - Preserves the compact branch for all follow-up messages in that conversation\n  - Prevents unnecessary branching when continuing compact conversations\n\n**API Endpoints:**\n\n- `/api/conversations` - Get conversations grouped by conversation_id with branch information\n- Query parameters: `domain` (filter by domain), `limit` (max conversations)\n\n**Database Schema:**\n\n- `conversation_id` - UUID identifying the conversation\n- `current_message_hash` - Hash of the last message in the request\n- `parent_message_hash` - Hash of the previous message (null for first message)\n- `system_hash` - Hash of the system prompt (for tracking context changes)\n- `branch_id` - Branch identifier (defaults to 'main', auto-generated for new branches)\n- `parent_request_id` - Direct link to the parent request in the conversation chain\n\n**Dashboard Features:**\n\n- **Conversations View** - Visual timeline showing message flow and branches\n- **Branch Visualization** - Blue nodes indicate branch points\n- **Branch Labels** - Non-main branches are labeled with their branch ID\n- **Conversation Grouping** - All related requests grouped under one conversation\n- **Multiple Tool Display** - Messages with multiple tool_use or tool_result blocks are properly displayed with visual separation (horizontal rules between each tool invocation)\n- **Duplicate Filtering** - Duplicate tool_use and tool_result blocks (same ID) are automatically filtered out\n- **System Reminder Filtering** - System reminder text blocks are hidden from display\n\n### Authentication Flow\n\n**Client Authentication (Proxy Level):**\n\n1. Extract domain from Host header\n2. Check for `client_api_key` in domain credential file\n3. Verify Bearer token against stored key using timing-safe comparison\n4. Return 401 Unauthorized if invalid\n\n**Claude API Authentication:**\n\n1. Check domain-specific credential files (`<domain>.credentials.json`)\n2. Use Authorization header from request\n\n### OAuth Support\n\n- Auto-refresh tokens 1 minute before expiry\n- Stores refreshed tokens back to credential files\n- Adds `anthropic-beta: oauth-2025-04-20` header\n\n### Token Tracking\n\n**In-Memory Tracking (Legacy)**\n\n- Per-domain statistics\n- Request type classification (query evaluation vs inference)\n- Tool call counting\n- Available at `/token-stats` endpoint\n\n**Comprehensive Token Usage Tracking (New)**\n\n- Tracks ALL request types (including query_evaluation and quota)\n- Persistent storage in partitioned `token_usage` table\n- 5-hour rolling window support for monitoring Claude API limits\n- Per-account AND per-domain tracking\n- API endpoints:\n  - `/api/token-usage/current` - Current window usage\n  - `/api/token-usage/daily` - Historical daily usage data\n  - `/api/conversations` - Conversations with account info\n- **Note**: Rate limiting is handled by Claude API directly. The proxy only tracks and displays usage statistics.\n\n### Storage\n\n- PostgreSQL for request/response data\n- Write-only access from proxy\n- Read-only access from dashboard\n- Automatic batch processing\n- **Conversation Grouping**: Requests are automatically grouped by conversation using message hashing\n\n### Debug Logging\n\nWhen `DEBUG=true`:\n\n- Logs full request/response (with sensitive data masked)\n- Shows streaming chunks\n- Masks patterns: `sk-ant-****`, `Bearer ****`\n- Includes SQL query stack traces\n\n### SQL Query Logging\n\nEnable SQL query logging in debug mode:\n\n```bash\n# Option 1: Enable all debug logging (includes SQL)\nDEBUG=true bun run dev\n\n# Option 2: Enable only SQL query logging\nDEBUG_SQL=true bun run dev\n\n# Option 3: Set in .env file\nDEBUG_SQL=true\n```\n\nSQL logging features:\n\n- All queries with parameters\n- Query execution time\n- Row counts\n- Slow query warnings (default: >5 seconds)\n- Failed query errors with details\n\n## Environment Variables\n\n**Essential:**\n\n- `DATABASE_URL` - PostgreSQL connection\n- `DASHBOARD_API_KEY` - Dashboard authentication\n\n**Optional:**\n\n- `DEBUG` - Enable debug logging\n- `DEBUG_SQL` - Enable SQL query logging (default: false)\n- `STORAGE_ENABLED` - Enable storage (default: false)\n- `SLACK_WEBHOOK_URL` - Slack notifications\n- `CREDENTIALS_DIR` - Domain credential directory\n- `COLLECT_TEST_SAMPLES` - Collect request samples for testing (default: false)\n- `TEST_SAMPLES_DIR` - Directory for test samples (default: test-samples)\n- `ENABLE_CLIENT_AUTH` - Enable client API key authentication (default: true). Set to false to allow anyone to use the proxy without authentication\n- `DASHBOARD_CACHE_TTL` - Dashboard cache TTL in seconds (default: 30). Set to 0 to disable caching\n- `SLOW_QUERY_THRESHOLD_MS` - Threshold in milliseconds for logging slow SQL queries (default: 5000)\n- `CLAUDE_API_TIMEOUT` - Timeout for Claude API requests in milliseconds (default: 600000 / 10 minutes)\n- `PROXY_SERVER_TIMEOUT` - Server-level timeout in milliseconds (default: 660000 / 11 minutes)\n- `STORAGE_ADAPTER_CLEANUP_MS` - Interval for cleaning up orphaned request ID mappings in milliseconds (default: 300000 / 5 minutes)\n- `STORAGE_ADAPTER_RETENTION_MS` - Retention time for request ID mappings in milliseconds (default: 3600000 / 1 hour)\n- `API_KEY_SALT` - Salt for hashing API keys in database (default: 'claude-nexus-proxy-default-salt')\n- `SPARK_API_URL` - Spark API base URL for recommendation feedback (default: 'http://localhost:8000')\n- `SPARK_API_KEY` - API key for authenticating with Spark API\n\n## Important Notes\n\n### Request Metadata\n\n- Query evaluation and quota are not part of the conversation, they serve as metadata queries\n\n## Testing & Type Safety\n\n**Type Checking:**\n\n- Run `bun run typecheck` before committing\n- Type checking is automatic during builds\n- Fix all type errors before deploying\n- **TypeScript Project References**: The monorepo uses TypeScript Project References for proper dependency management\n  - Automatically handles build order between packages\n  - Generates declaration files for cross-package imports\n  - Run `tsc --build` at the root to type check all packages\n  - See ADR-013 for details on this architectural decision\n\n**Test Sample Collection:**\nThe proxy can collect real request samples for test development:\n\n- Enable with `COLLECT_TEST_SAMPLES=true`\n- Samples are stored in `test-samples/` directory\n- Each request type gets its own file (e.g., `inference_streaming_opus.json`)\n- Sensitive data is automatically masked\n- Samples include headers, body, and metadata\n\n**Tests:**\nCurrently no automated tests. When implementing:\n\n- Use Bun's built-in test runner\n- Test proxy logic, telemetry, token tracking\n- Test both streaming and non-streaming responses\n- Use collected samples as test data\n\n## Important Notes\n\n- Uses Bun runtime exclusively (no Node.js)\n- Separate Docker images for each service\n- TypeScript compilation for production builds\n- Model-agnostic (accepts any model name)\n\n## Database Schema\n\n### Main Tables\n\n**api_requests** - Stores all API requests and responses with token tracking:\n\n- `account_id` - Account identifier from credential files for per-account tracking\n- `input_tokens`, `output_tokens`, `total_tokens` - Token usage metrics\n- `conversation_id`, `branch_id` - Conversation tracking\n- `current_message_hash`, `parent_message_hash` - Message linking\n- `parent_task_request_id`, `is_subtask`, `task_tool_invocation` - Sub-task tracking\n\n**streaming_chunks** - Stores streaming response chunks\n\n### Account-Based Token Tracking\n\nToken usage is tracked directly in the `api_requests` table:\n\n- Each request is associated with an `account_id` from the credential file\n- Token counts are stored per request for accurate tracking\n- Queries aggregate usage by account and time window\n\n### Database Schema Evolution\n\n**Schema Management:**\n\n- Initial schema: `scripts/init-database.sql`\n- Migrations: `scripts/db/migrations/` (TypeScript files)\n- Auto-initialization: `writer.ts` uses init SQL file when tables don't exist\n\n**Running Migrations:**\n\n```bash\n# Run a specific migration\nbun run scripts/db/migrations/001-add-conversation-tracking.ts\n\n# Run all migrations in order\nfor file in scripts/db/migrations/*.ts; do bun run \"$file\"; done\n```\n\n**Available Migrations:**\n\n- 000: Initial database setup\n- 001: Add conversation tracking\n- 002: Optimize conversation indexes\n- 003: Add sub-task tracking\n- 004: Optimize window function queries\n- 005: Populate account IDs\n\nSee `docs/04-Architecture/ADRs/adr-012-database-schema-evolution.md` for details.\n\n## Common Tasks\n\n### Add Domain Credentials\n\n```bash\n# Generate secure client API key\nbun run scripts/generate-api-key.ts\n\n# Create credential file\ncat > credentials/domain.com.credentials.json << EOF\n{\n  \"type\": \"api_key\",\n  \"accountId\": \"acc_f9e1c2d3b4a5\",  # Unique account identifier\n  \"api_key\": \"sk-ant-...\",\n  \"client_api_key\": \"cnp_live_...\"\n}\nEOF\n```\n\n### Enable Storage\n\n```bash\nexport STORAGE_ENABLED=true\nexport DATABASE_URL=postgresql://...\n```\n\n### View Token Stats\n\n```bash\ncurl http://localhost:3000/token-stats\n```\n\n### Access Dashboard\n\n```bash\nopen http://localhost:3001\n# Use DASHBOARD_API_KEY for authentication\n# Auth header: X-Dashboard-Key: <your-key>\n```\n\n## Sub-task Tracking & Visualization\n\n### Sub-task Detection\n\nThe proxy automatically detects and tracks sub-tasks spawned using the Task tool:\n\n**Database Fields:**\n\n- `parent_task_request_id` - Links sub-task requests to their parent task\n- `is_subtask` - Boolean flag indicating if a request is a sub-task\n- `task_tool_invocation` - JSONB array storing Task tool invocations\n\n**Sub-task Linking:**\n\n- Sub-tasks are linked by matching the user message to Task tool invocation prompts\n- The system creates parent-child relationships between tasks and their sub-tasks\n- Multiple sub-tasks can be spawned from a single parent request\n\n### Dashboard Visualization\n\n**Conversation Tree:**\n\n- Sub-task nodes appear as separate gray boxes to the right of parent nodes\n- Format: \"sub-task N (M)\" where N is the sub-task number and M is the message count\n- Sub-task boxes are clickable and link to their conversation\n- Hover over sub-task boxes to see the task prompt in a tooltip\n\n**Stats Display:**\n\n- \"Total Sub-tasks\" panel shows count of all sub-tasks in a conversation\n- Sub-task indicators on parent nodes show number of spawned tasks\n\n**Visual Design:**\n\n- Sub-task boxes: 100x36px gray boxes with 150px right offset\n- Tooltips: 250x130px with gradient background, appear above nodes on hover\n- Connected to parent nodes with horizontal edges\n\n## Important Implementation Notes\n\n### Conversation Hash Filtering\n\nWhen generating message hashes for conversation tracking, the system filters out:\n\n- Content items that start with `<system-reminder>`\n- This prevents conversation linking from breaking when Claude adds system reminders\n\n### Dashboard Authentication\n\n- Uses `X-Dashboard-Key` header (not Authorization)\n- Cookie-based auth also supported for browser sessions\n\n### Spark Tool Integration\n\nThe dashboard supports the Spark recommendation tool (`mcp__spark__get_recommendation`):\n\n**Features:**\n\n- Automatic detection of Spark tool usage in conversations\n- Display of recommendations in a formatted view\n- Feedback UI for rating and commenting on recommendations\n- Batch fetching of existing feedback\n- Integration with Spark API for feedback submission\n\n**Configuration:**\n\n1. Set `SPARK_API_URL` and `SPARK_API_KEY` environment variables\n2. The dashboard will automatically detect Spark recommendations in tool_result messages\n3. Users can submit feedback directly from the request details page\n4. The proxy logs Spark configuration at startup:\n   - When configured: Shows URL and confirms API key is set\n   - When not configured: Shows \"SPARK_API_KEY not set\"\n\n**API Endpoints:**\n\n- `POST /api/spark/feedback` - Submit feedback for a recommendation\n- `GET /api/spark/sessions/:sessionId/feedback` - Get feedback for a specific session\n- `POST /api/spark/feedback/batch` - Get feedback for multiple sessions\n\n**Security Note:**\n\nThe dashboard authentication cookie (`dashboard_auth`) is set with `httpOnly: false` to allow JavaScript access for making authenticated API calls from the browser to the proxy service. This is a security trade-off that enables the inline feedback component to work. Consider implementing a more secure approach such as:\n\n- Using a separate API token for browser-based requests\n- Implementing a server-side proxy endpoint in the dashboard\n- Using session-based authentication with CSRF tokens\n\n### SQL Query Optimization\n\n- Always include all required fields in SELECT statements\n- Missing fields like `parent_task_request_id`, `is_subtask`, `task_tool_invocation` will break sub-task tracking\n- Use the SLOW_QUERY_THRESHOLD_MS env var to monitor query performance\n\n### Check Token Usage\n\n```bash\n# Current 5-hour window usage\ncurl \"http://localhost:3000/api/token-usage/current?accountId=acc_f9e1c2d3b4a5&window=300\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n\n# Daily usage (last 30 days)\ncurl \"http://localhost:3000/api/token-usage/daily?accountId=acc_f9e1c2d3b4a5&aggregate=true\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n\n# View conversations\ncurl \"http://localhost:3000/api/conversations?accountId=acc_f9e1c2d3b4a5\" \\\n  -H \"X-Dashboard-Key: $DASHBOARD_API_KEY\"\n```\n\n### Copy Conversation Between Databases\n\n```bash\n# Copy a conversation from one database to another\nbun run db:copy-conversation --conversation-id <uuid> --dest-db <url> [options]\n\n# Example: Copy to staging database (same table names)\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\"\n\n# Dry run to preview what would be copied\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" --dry-run\n\n# Copy with streaming chunks\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" --include-chunks\n\n# Use custom table names (e.g., from api_requests to api_requests_backup)\nbun run db:copy-conversation --conversation-id 123e4567-e89b-12d3-a456-426614174000 \\\n  --dest-db \"postgresql://user:pass@staging-host:5432/staging_db\" \\\n  --source-table api_requests --dest-table api_requests_backup\n```\n\n## Maintenance\n\n### Grooming\n\nThe process of `grooming` is used to keep a clean repository. It should be performed regularly and rely on [GROOMING.md](GROOMING.md)\n\n# important-instruction-reminders\nDo what has been asked; nothing more, nothing less.\nNEVER create files unless they're absolutely necessary for achieving your goal.\nALWAYS prefer editing an existing file to creating a new one.\nNEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.\n\n      \n      IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context or otherwise consider it in your response unless it is highly relevant to your task. Most of the time, it is not relevant.\n</system-reminder>\n",
              "type": "text"
            },
            {
              "text": "Count all files in the codebase, broken down by:\n1. Total number of files\n2. Files by type/extension (e.g., .ts, .json, .md, etc.)\n3. Files per directory (services/proxy, services/dashboard, packages/shared, etc.)\n\nProvide a summary with the counts organized in a clear format.",
              "type": "text",
              "cache_control": {
                "type": "ephemeral"
              }
            }
          ]
        }
      ],
      "metadata": {
        "user_id": "claude-1"
      },
      "max_tokens": 32000,
      "temperature": 1
    }
  }
}
